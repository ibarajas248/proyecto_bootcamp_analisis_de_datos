{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5jxwcKAZ5FvbPaPdYrFvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibarajas248/proyecto_bootcamp_analisis_de_datos/blob/master/webscrapping_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFCVmr1oLOoQ",
        "outputId": "1aa59102-4bba-431e-c925-aae86089d9d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22TEA_UhLlg6",
        "outputId": "bd96bc16-d4f4-4023-fc7e-77269740d92e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.0.0-cp310-cp310-manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Downloading mysql_connector_python-9.0.0-cp310-cp310-manylinux_2_17_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBUO2xn6K_MK",
        "outputId": "37702ba4-28ca-49ce-8db7-ba62cc27cccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partido: Marsella 4 - 0 Toulouse 2018-08-10 13:45:00 https://as.com/futbol/2018/08/10/internacional/1533926597_792000.html\n",
            "Partido: Nantes 1 - 3 Mónaco 2018-08-11 10:00:00 https://colombia.as.com/colombia/2018/08/11/futbol/1534006734_369699.html\n",
            "Partido: Montpellier 1 - 2 Dijon 2018-08-11 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241620/\n",
            "Partido: Angers 3 - 4 Nîmes 2018-08-11 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241615/\n",
            "Partido: Lille 3 - 1 Rennes 2018-08-11 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241617/\n",
            "Partido: Niza 0 - 1 Stade de Reims 2018-08-11 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241622/\n",
            "Partido: Saint-Etienne 2 - 1 Guingamp 2018-08-11 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241624/\n",
            "Partido: Lyon 2 - 0 Amiens 2018-08-12 08:00:00 https://as.com/futbol/2018/08/12/internacional/1534052095_230341.html\n",
            "Partido: Girondins 0 - 2 Estrasburgo 2018-08-12 10:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241616/\n",
            "Partido: PSG 3 - 0 Caen 2018-08-12 14:00:00 https://as.com/futbol/2018/08/12/internacional/1534052609_580157.html\n",
            "Error al extraer goleadores locales en https://as.com/futbol/2018/08/10/internacional/1533926597_792000.html\n",
            "No se encontraron goleadores visitantes en https://as.com/futbol/2018/08/10/internacional/1533926597_792000.html\n",
            "Error al extraer goleadores locales en https://colombia.as.com/colombia/2018/08/11/futbol/1534006734_369699.html\n",
            "No se encontraron goleadores visitantes en https://colombia.as.com/colombia/2018/08/11/futbol/1534006734_369699.html\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241620/\n",
            "Goleadores registrados para el partido ID 10002 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241620/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_1_241620/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241615/\n",
            "Goleadores registrados para el partido ID 10003 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241615/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_1_241615/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241617/\n",
            "Goleadores registrados para el partido ID 10004 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241617/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_1_241617/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241622/\n",
            "Goleadores registrados para el partido ID 10005 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241622/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_1_241622/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241624/\n",
            "Goleadores registrados para el partido ID 10006 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241624/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_1_241624/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "No se encontraron goleadores visitantes en https://as.com/futbol/2018/08/12/internacional/1534052095_230341.html\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241616/\n",
            "Goleadores registrados para el partido ID 10008 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_1_241616/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_1_241616/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "No se encontraron goleadores visitantes en https://as.com/futbol/2018/08/12/internacional/1534052609_580157.html\n",
            "Partidos insertados exitosamente en la base de datos.\n",
            "Partido: Stade de Reims 1 - 0 Lyon 2018-08-17 13:45:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241631/\n",
            "Partido: Guingamp 1 - 3 PSG 2018-08-18 10:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241628/\n",
            "Partido: Mónaco 0 - 0 Lille 2018-08-18 13:00:00 https://colombia.as.com/colombia/2018/08/18/futbol/1534623191_935574.html\n",
            "Partido: Dijon 2 - 0 Nantes 2018-08-18 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241627/\n",
            "Partido: Caen 1 - 1 Niza 2018-08-18 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241626/\n",
            "Partido: Rennes 1 - 0 Angers 2018-08-18 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241632/\n",
            "Partido: Amiens 1 - 2 Montpellier 2018-08-18 13:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241625/\n",
            "Partido: Estrasburgo 1 - 1 Saint-Etienne 2018-08-19 08:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241633/\n",
            "Partido: Toulouse 2 - 1 Girondins 2018-08-19 10:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241634/\n",
            "Partido: Nîmes 3 - 1 Marsella 2018-08-19 14:00:00 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241630/\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241631/\n",
            "No se encontraron goleadores visitantes en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241631/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_2_241631/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241628/\n",
            "Goleadores registrados para el partido ID 10011 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241628/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_2_241628/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/colombia/2018/08/18/futbol/1534623191_935574.html\n",
            "No se encontraron goleadores visitantes en https://colombia.as.com/colombia/2018/08/18/futbol/1534623191_935574.html\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241627/\n",
            "Goleadores registrados para el partido ID 10013 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241627/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_2_241627/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241626/\n",
            "Goleadores registrados para el partido ID 10014 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241626/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_2_241626/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241632/\n",
            "No se encontraron goleadores visitantes en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241632/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_2_241632/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n",
            "Error al extraer goleadores locales en https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241625/\n",
            "Goleadores registrados para el partido ID 10016 https://colombia.as.com/resultados/futbol/francia/2018_2019/directo/regular_a_2_241625/\n",
            "Texto: ESTADÍSTICAS, Enlace: https://colombia.as.com//resultados/futbol/francia/2018_2019/directo/regular_a_2_241625/estadisticas/\n",
            "Iniciando scraping de estadísticas...\n",
            "Datos insertados correctamente.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import mysql.connector\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def clean_minute_format(gol):\n",
        "    return gol.split('(')[0]\n",
        "\n",
        "def extraer_nombre(scorer):\n",
        "    match = re.match(r\"([^\\d]+)\", scorer)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return scorer.strip()\n",
        "\n",
        "def insertar_goleadores(cursor, conn, partido_id, scorers, equipo):\n",
        "    for scorer in scorers:\n",
        "        partes = scorer.rsplit(', ', 1)\n",
        "        if len(partes) == 2:\n",
        "            jugador = extraer_nombre(partes[0])\n",
        "            minutos_str = partes[1].replace(\"'\", '')\n",
        "\n",
        "            minutos_list = minutos_str.split(', ')\n",
        "            for minuto in minutos_list:\n",
        "                if minuto:\n",
        "                    cursor.execute(\n",
        "                        'INSERT INTO goles (partido_id, jugador, equipo, minuto_marcaje) VALUES (%s, %s, %s, %s)',\n",
        "                        (partido_id, jugador, equipo, int(minuto))\n",
        "                    )\n",
        "        else:\n",
        "            jugador = extraer_nombre(partes[0])\n",
        "            cursor.execute(\n",
        "                'INSERT INTO goles (partido_id, jugador, equipo, minuto_marcaje) VALUES (%s, %s, %s, NULL)',\n",
        "                (partido_id, jugador, equipo)\n",
        "            )\n",
        "    conn.commit()\n",
        "\n",
        "def insertPartidos():\n",
        "    year = 2018\n",
        "    id_tabla_partido = 10000\n",
        "    cambio_mes = False\n",
        "\n",
        "\n",
        "    for numero in range(1, 30):\n",
        "        url = f'https://colombia.as.com/resultados/futbol/francia/2018_2019/jornada/regular_a_{numero}'\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            partidos = []\n",
        "            partidosConURL = []\n",
        "            for partido in soup.find_all('li', class_='list-resultado'):\n",
        "                local = partido.find('div', class_='equipo-local').find('span', class_='nombre-equipo').text\n",
        "\n",
        "                try:\n",
        "                    resultado_str = partido.find('div', class_='cont-resultado').find('a', class_='resultado')\n",
        "                    if resultado_str:\n",
        "                        resultado_str = resultado_str.text.strip()\n",
        "                    else:\n",
        "                        resultado_str = None\n",
        "\n",
        "                    if not resultado_str:\n",
        "                        resultado_str_sin_comenzar = partido.find('div', class_='cont-resultado no-comenzado').find('a', class_='resultado')\n",
        "                        if resultado_str_sin_comenzar:\n",
        "                            resultado_str = resultado_str_sin_comenzar.text.strip()\n",
        "                        else:\n",
        "                            resultado_str = None\n",
        "\n",
        "                    if resultado_str:\n",
        "                        try:\n",
        "                            goles_local, goles_visitante = resultado_str.split('-')\n",
        "                            goles_local = int(goles_local.strip())\n",
        "                            goles_visitante = int(goles_visitante.strip())\n",
        "                        except:\n",
        "                            goles_local, goles_visitante = None, None\n",
        "                    else:\n",
        "                        goles_local, goles_visitante = None, None\n",
        "\n",
        "                except AttributeError as e:\n",
        "                    print(f\"Error al obtener el resultado del partido: {e}\")\n",
        "                    resultado_str, partido_url = None, None\n",
        "                    goles_local, goles_visitante = None, None\n",
        "\n",
        "                try:\n",
        "                    partido_url = partido.find('div', class_='cont-resultado').find('a', class_='resultado')['href']\n",
        "                except:\n",
        "                    partido_url = None\n",
        "\n",
        "\n",
        "\n",
        "                #Extraer jornada\n",
        "                cont_paginador = soup.find('div', class_='cont-paginador cf')\n",
        "\n",
        "                if cont_paginador:\n",
        "                    # Extraer todas las jornadas\n",
        "                    jornadas = cont_paginador.find_all('span', class_='tit-jornada')\n",
        "\n",
        "                    if jornadas:\n",
        "                        # Suponiendo que la jornada actual es el primer elemento en la lista\n",
        "                        jornada_actual = jornadas[0].get_text(strip=True)\n",
        "                        jornada_numero = (re.search(r'\\d+', jornada_actual)).group()\n",
        "\n",
        "\n",
        "                    else:\n",
        "                        jornada_numero= None\n",
        "                else:\n",
        "                    jornada_numero= None\n",
        "\n",
        "                try:\n",
        "                   # liga = soup.find('div', class_='header-seccion').find('h1', class_='tit-seccion').find('a').get_text(strip=True);\n",
        "                    liga = soup.find('span', class_='tit-subtitle-info').get_text(strip=True);\n",
        "                except:\n",
        "                    liga = (\"dato no encontrado\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                visitante = partido.find('div', class_='equipo-visitante').find('span', class_='nombre-equipo').text\n",
        "                fecha_str = partido.find('div', class_='info-evento').find('span', class_='fecha').text.strip()\n",
        "                match = re.search(r'([A-Z])-(\\d{2}/\\d{2} \\d{2}:\\d{2})', fecha_str)\n",
        "                if match:\n",
        "                    dia_semana = match.group(1)\n",
        "                    fecha_hora = match.group(2)\n",
        "                    fecha_str_con_año = f'{year} {fecha_hora}'\n",
        "                    try:\n",
        "                        fecha = datetime.strptime(fecha_str_con_año, '%Y %d/%m %H:%M')\n",
        "\n",
        "\n",
        "                        if fecha.month == 1 and cambio_mes==False :  # January of the following year\n",
        "                            year += 1  # Increment the year to 2025\n",
        "                            fecha = fecha.replace(year=year)  # Update the date with the new year\n",
        "                            cambio_mes= True\n",
        "\n",
        "                    except ValueError as e:\n",
        "                        print(f'Error al convertir fecha {fecha_str_con_año}: {e}')\n",
        "                        continue\n",
        "                else:\n",
        "                    print(f'Formato de fecha no reconocido para {fecha_str}')\n",
        "                    continue\n",
        "\n",
        "                partidos.append((id_tabla_partido, local, goles_local, goles_visitante, visitante, fecha, jornada_numero, liga))\n",
        "\n",
        "                if partido_url:\n",
        "                    partidosConURL.append(\n",
        "                        (id_tabla_partido, local, goles_local, goles_visitante, visitante, fecha, partido_url))\n",
        "                    print(f'Partido: {local} {goles_local} - {goles_visitante} {visitante} {fecha} {partido_url}')\n",
        "\n",
        "                id_tabla_partido += 1\n",
        "\n",
        "            #conexion localhost\n",
        "            \"\"\"\n",
        "            conn = mysql.connector.connect(\n",
        "                host='localhost',\n",
        "                port=3310,\n",
        "                user='root',\n",
        "                password='',\n",
        "                database='futbol'\n",
        "            )\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "            #conexión clever cloud\n",
        "\n",
        "            conn = mysql.connector.connect(\n",
        "                host='bnlrjjogqqtrux5dkhx3-mysql.services.clever-cloud.com',\n",
        "                port=3306,\n",
        "                user='ug9k8pdx4fu2lc9p',\n",
        "                password='MiyaArHakCa5tGKIRcec',\n",
        "                database='bnlrjjogqqtrux5dkhx3'\n",
        "            )\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS partidos (\n",
        "                id INT primary key,\n",
        "                local VARCHAR(255),\n",
        "                goles_local INT,\n",
        "                goles_visitante INT,\n",
        "                visitante VARCHAR(255),\n",
        "                fecha DATETIME,\n",
        "                jornada VARCHAR(50) null,\n",
        "                liga VARCHAR(100) null\n",
        "\n",
        "            )\n",
        "            ''')\n",
        "            cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS goles (\n",
        "                id INT AUTO_INCREMENT primary key,\n",
        "                partido_id INT,\n",
        "                jugador VARCHAR(255),\n",
        "                equipo VARCHAR(255),\n",
        "                minuto_marcaje INT,\n",
        "                FOREIGN KEY (partido_id) REFERENCES partidos(id) ON DELETE CASCADE\n",
        "            )\n",
        "            ''')\n",
        "\n",
        "            if numero == 1:\n",
        "                cursor.execute('DELETE FROM goles')\n",
        "                cursor.execute('DELETE FROM partidos')\n",
        "\n",
        "            cursor.executemany(\n",
        "                'INSERT INTO partidos (id, local, goles_local, goles_visitante, visitante, fecha, jornada,liga) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)',\n",
        "                partidos)\n",
        "            try:\n",
        "                procesar_goles(cursor, conn, partidosConURL)\n",
        "            except Exception as e:\n",
        "                print(f\"No hay información de goles: {e}\")\n",
        "\n",
        "            conn.commit()\n",
        "            conn.close()\n",
        "            print('Partidos insertados exitosamente en la base de datos.')\n",
        "\n",
        "\n",
        "def scraping_stadisticas(cursor, conn, estadistica, partido_id):\n",
        "    print(\"Iniciando scraping de estadísticas...\")\n",
        "\n",
        "    # URL de la página a scrapear\n",
        "    url = estadistica\n",
        "\n",
        "    try:\n",
        "        # Realiza la solicitud HTTP\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Lanza una excepción si la solicitud falla\n",
        "\n",
        "        # Analiza el contenido HTML\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Crear la tabla si no existe\n",
        "        create_table_query = \"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS estadisticas (\n",
        "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "                id_partido INT NULL,\n",
        "                equipo VARCHAR(70) NULL,\n",
        "                intervenciones_portero INT,\n",
        "                tarjetas_amarillas INT NULL,\n",
        "                tarjeta_roja INT NULL,\n",
        "                faltas_recibidas INT NULL,\n",
        "                faltas_cometidas INT NULL,\n",
        "                balones_perdidos INT NULL,\n",
        "                balones_recuperados INT NULL,\n",
        "                fuera_de_juego_en_contra INT NULL,\n",
        "                FOREIGN KEY (id_partido) REFERENCES partidos(id) ON DELETE CASCADE\n",
        "            )\n",
        "        \"\"\"\n",
        "        cursor.execute(create_table_query)\n",
        "\n",
        "        # Extraer los nombres de los equipos\n",
        "        teams = soup.find_all('a', class_='team-banner')\n",
        "        team_names = [team.find('span', class_='team-name').text.strip() for team in teams]\n",
        "\n",
        "        # Extraer las estadísticas\n",
        "        stats = {}\n",
        "        stats['intervenciones_portero'] = [int(span.text) for span in\n",
        "                                           soup.find_all('div', class_='stat-wr')[1].find_all('span',\n",
        "                                                                                              class_='stat-val')]\n",
        "        stats['tarjetas_amarillas'] = [int(span.text) for span in\n",
        "                                       soup.find_all('div', class_='stat-wr')[2].find_all('span', class_='stat-val')]\n",
        "        stats['tarjetas_rojas'] = [int(span.text) for span in\n",
        "                                   soup.find_all('div', class_='stat-wr')[3].find_all('span', class_='stat-val')]\n",
        "\n",
        "        stats['faltas_recibidas'] = [int(span.text) for span in\n",
        "                                     soup.find_all('div', class_='stat-wr')[5].find_all('span', class_='stat-val')]\n",
        "\n",
        "        stats['faltas_cometidas'] = [int(span.text) for span in\n",
        "                                     soup.find_all('div', class_='stat-wr')[5].find_all('span', class_='stat-val')]\n",
        "        stats['balones_perdidos'] = [int(span.text) for span in\n",
        "                                     soup.find_all('div', class_='stat-wr')[6].find_all('span', class_='stat-val')]\n",
        "        stats['balones_recuperados'] = [int(span.text) for span in\n",
        "                                        soup.find_all('div', class_='stat-wr')[7].find_all('span', class_='stat-val')]\n",
        "        stats['fueras_de_juego_en_contra'] = [int(span.text) for span in\n",
        "                                              soup.find_all('div', class_='stat-wr')[8].find_all('span',\n",
        "                                                                                                 class_='stat-val')]\n",
        "\n",
        "        # Insertar las estadísticas en la base de datos\n",
        "        for i in range(2):  # Asumiendo que siempre hay dos equipos\n",
        "            equipo = team_names[i]\n",
        "            intervenciones_portero = stats['intervenciones_portero'][i]\n",
        "            tarjetas_amarillas = stats['tarjetas_amarillas'][i]\n",
        "            tarjetas_rojas = stats['tarjetas_rojas'][i]\n",
        "            faltas_recibidas = stats['faltas_recibidas'][i]\n",
        "            faltas_cometidas = stats['faltas_cometidas'][i]\n",
        "            balones_perdidos = stats['balones_perdidos'][i]\n",
        "            balones_recuperados = stats['balones_recuperados'][i]\n",
        "            fueras_de_juego_en_contra = stats['fueras_de_juego_en_contra'][i]\n",
        "\n",
        "            insert_query = \"\"\"\n",
        "                INSERT INTO estadisticas (\n",
        "                    id_partido, equipo, intervenciones_portero, tarjetas_amarillas,\n",
        "                    tarjeta_roja,faltas_recibidas, faltas_cometidas, balones_perdidos,\n",
        "                    balones_recuperados, fuera_de_juego_en_contra\n",
        "                ) VALUES (%s, %s, %s, %s,%s, %s, %s, %s, %s, %s)\n",
        "            \"\"\"\n",
        "            cursor.execute(insert_query, (\n",
        "                partido_id, equipo, intervenciones_portero, tarjetas_amarillas,\n",
        "                tarjetas_rojas,faltas_recibidas, faltas_cometidas, balones_perdidos,\n",
        "                balones_recuperados, fueras_de_juego_en_contra\n",
        "            ))\n",
        "\n",
        "        conn.commit()\n",
        "        print(\"Datos insertados correctamente.\")\n",
        "\n",
        "        return stats\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error al realizar la solicitud HTTP: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def procesar_goles(cursor, conn, partidosConURL):\n",
        "    for partido_data in partidosConURL:\n",
        "        partido_id = partido_data[0]\n",
        "        partido_url = partido_data[6]\n",
        "        response_partido = requests.get(partido_url)\n",
        "\n",
        "        if response_partido.status_code == 200:\n",
        "            soup_partido = BeautifulSoup(response_partido.content, 'html.parser')\n",
        "\n",
        "            try:\n",
        "                local_scorers_tag = soup_partido.find('div', class_='scr-hdr__team is-local').find('div', class_='scr-hdr__scorers')\n",
        "                if local_scorers_tag:\n",
        "                    local_scorers = [scorer.text.strip() for scorer in local_scorers_tag.find_all('span')]\n",
        "                else:\n",
        "                    local_scorers = []\n",
        "                if not local_scorers:\n",
        "                    teams = soup_partido.find_all('div', class_='team team-a')\n",
        "                    for team in teams:\n",
        "                        scorers_div = team.find('div', class_='scorers')\n",
        "                        if scorers_div:\n",
        "                            local_scorers = [scorer.text.strip() for scorer in scorers_div.find_all('span')]\n",
        "                            break\n",
        "\n",
        "                if local_scorers:\n",
        "                    insertar_goleadores(cursor, conn, partido_id, local_scorers, partido_data[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                else:\n",
        "                    print(f\"No se encontraron goleadores locales en {partido_url}\")\n",
        "\n",
        "            except AttributeError:\n",
        "                print(f\"Error al extraer goleadores locales en {partido_url}\")\n",
        "\n",
        "            try:\n",
        "                visitante_scorers_tag = soup_partido.find('div', class_='scr-hdr__team is-visitor')\n",
        "                if visitante_scorers_tag:\n",
        "                    scorers_div = visitante_scorers_tag.find('div', class_='scr-hdr__scorers')\n",
        "                    if scorers_div:\n",
        "                        visitante_scorers = [scorer.text.strip() for scorer in scorers_div.find_all('span')]\n",
        "                    else:\n",
        "                        visitante_scorers = []\n",
        "                else:\n",
        "                    visitante_scorers = []\n",
        "\n",
        "                if not visitante_scorers:\n",
        "                    teams = soup_partido.find_all('div', class_='team team-b')\n",
        "                    for team in teams:\n",
        "                        scorers_div = team.find('div', class_='scorers')\n",
        "                        if scorers_div:\n",
        "                            visitante_scorers = [scorer.text.strip() for scorer in scorers_div.find_all('span')]\n",
        "                            break\n",
        "\n",
        "                if visitante_scorers:\n",
        "                    insertar_goleadores(cursor, conn, partido_id, visitante_scorers, partido_data[4])\n",
        "                    print(f'Goleadores registrados para el partido ID {partido_id} ' + f'{partido_url}')\n",
        "                else:\n",
        "                    print(f\"No se encontraron goleadores visitantes en {partido_url}\")\n",
        "\n",
        "            except AttributeError:\n",
        "                print(f\"Error al extraer goleadores visitantes en {partido_url}\")\n",
        "\n",
        "            #Extrae URL\n",
        "            nav = soup_partido.find('nav', class_='nav-hor-wr sh')\n",
        "            if nav:\n",
        "                # Encontrar todos los elementos <a> dentro del nav\n",
        "                links = nav.find_all('a')\n",
        "\n",
        "                for link in links:\n",
        "                    href = link.get('href')\n",
        "                    text = link.get_text(strip=True)\n",
        "                    if text == \"ESTADÍSTICAS\":\n",
        "                        estadistica = \"https://colombia.as.com/\" + href;\n",
        "                        print(f\"Texto: {text}, Enlace: {estadistica}\")\n",
        "                        scraping_stadisticas(cursor, conn, estadistica,partido_id)\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f'Error al realizar la solicitud para {partido_url}: {response_partido.status_code}')\n",
        "\n",
        "insertPartidos()\n"
      ]
    }
  ]
}